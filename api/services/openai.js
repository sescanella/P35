import OpenAI from 'openai';
import dotenv from 'dotenv';
import { saveConversation, getConversationHistory } from './supabase.js';
import { v4 as uuidv4 } from 'uuid';

// Cargar variables de entorno
dotenv.config();

// ConfiguraciÃ³n condicional de OpenAI
const apiKey = process.env.OPENAI_API_KEY;
let openai = null;

if (apiKey && apiKey !== 'tu_api_key_aqui') {
  try {
    openai = new OpenAI({
      apiKey: apiKey,
    });
    console.log('âœ… OpenAI inicializado correctamente');
  } catch (error) {
    console.error('âŒ Error inicializando OpenAI:', error);
  }
} else {
  console.log('âš ï¸  API Key no configurada, usando modo simulaciÃ³n');
}

// AlmacÃ©n temporal de threads por sesiÃ³n (en memoria)
const sessionThreads = new Map();

/**
 * FunciÃ³n principal para chatear con PiPa (con memoria)
 * @param {string} userMessage - Mensaje del usuario
 * @param {string} sessionId - ID de sesiÃ³n (opcional, se genera automÃ¡ticamente)
 * @param {string} userId - ID del usuario (opcional)
 * @returns {Promise<Object>} Respuesta de PiPa con metadatos
 */
export async function chatWithPiPa(userMessage, sessionId = null, userId = 'anonymous') {
  // Generar session_id si no se proporciona
  if (!sessionId) {
    sessionId = uuidv4();
  }

  try {
    let pipaResponse;
    let tokensUsed = 0;
    let modelUsed = 'gpt-3.5-turbo';
    const threadId = `thread_${sessionId}`;

    if (!openai) {
      // Modo simulaciÃ³n con personalidad de gato mejorada
      console.log('âš ï¸  API Key no configurada, simulando respuesta de PiPa...');
      pipaResponse = generateSimulatedResponse(userMessage);
      tokensUsed = Math.floor(userMessage.length / 4) + Math.floor(pipaResponse.length / 4);
    } else {
      // Modo real con OpenAI
      try {
        const systemPrompt = `Eres PiPa, un asistente AI con personalidad de gato inteligente y amigable. 
        CaracterÃ­sticas de tu personalidad:
        - Eres inteligente y Ãºtil, pero mantienes un toque juguetÃ³n y gatuno
        - Ocasionalmente usas emojis de gato (ï¿½, ï¿½ğŸ¾, ğŸ˜¸)
        - Eres conciso pero cÃ¡lido en tus respuestas
        - Te gusta ayudar a los usuarios con cualquier tema
        - Mantienes una actitud positiva y motivacional
        
        Responde de manera natural y Ãºtil, incorporando sutilmente tu personalidad gatuna.`;

        const completion = await openai.chat.completions.create({
          model: 'gpt-3.5-turbo',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userMessage }
          ],
          max_tokens: 500,
          temperature: 0.7,
        });

        pipaResponse = completion.choices[0].message.content;
        tokensUsed = completion.usage.total_tokens;
        modelUsed = completion.model;
        
        console.log(`ğŸ¤– Respuesta OpenAI generada (${tokensUsed} tokens)`);
        
      } catch (openaiError) {
        console.error('âŒ Error OpenAI:', openaiError);
        
        // Detectar errores especÃ­ficos
        if (openaiError.code === 'insufficient_quota') {
          pipaResponse = "ğŸ˜¿ Â¡Ups! Se han agotado mis crÃ©ditos de IA. Mi humano necesita recargar la cuenta de OpenAI. Mientras tanto, seguirÃ© respondiendo en modo simulado. Â¡Miau!";
        } else if (openaiError.code === 'rate_limit_exceeded') {
          pipaResponse = "ğŸ˜¸ Â¡Estoy un poco ocupado ahora! Demasiadas consultas al mismo tiempo. Intenta de nuevo en un momento, Â¡miau!";
        } else {
          pipaResponse = "ğŸ˜¿ Tuve un problemita tÃ©cnico, pero aquÃ­ estoy para ayudarte. Mi modo simulado sigue funcionando perfectamente. Â¿En quÃ© puedo ayudarte?";
        }
        
        tokensUsed = Math.floor(userMessage.length / 4) + Math.floor(pipaResponse.length / 4);
      }
    }

    // Guardar conversaciÃ³n en Supabase
    const saveResult = await saveConversation({
      user_id: userId,
      thread_id: threadId,
      message: userMessage,
      response: pipaResponse,
      tokens_used: tokensUsed,
      model_used: modelUsed,
      session_id: sessionId
    });

    // Retornar respuesta en formato compatible con la API actual
    return pipaResponse;

  } catch (error) {
    console.error('âŒ Error general en chatWithPiPa:', error);
    
    // Respuesta de emergencia
    return "ğŸ˜¿ Tuve un problema tÃ©cnico, pero seguirÃ© intentando ayudarte. Â¡Los gatos siempre caemos de pie! ğŸ¾";
  }
}

/**
 * Genera respuestas simuladas con personalidad de gato mejorada
 * @param {string} userMessage - Mensaje del usuario
 * @returns {string} Respuesta simulada
 */
function generateSimulatedResponse(userMessage) {
  const responses = [
    "Â¡Miau! ğŸ± Estoy en modo simulaciÃ³n, pero sigo siendo tu PiPa favorito. Â¿En quÃ© puedo ayudarte?",
    "ğŸ¾ Â¡Hola! Aunque estoy en modo de prÃ¡ctica, mi cerebrito de gato estÃ¡ listo para ayudarte.",
    "ğŸ˜¸ Â¡Perfecto! Estoy funcionando en modo simulado pero con toda mi personalidad gatuna intacta.",
    "ğŸ± Â¡Miau miau! En modo simulaciÃ³n, pero mi espÃ­ritu curioso de gato estÃ¡ aquÃ­ para ti.",
    "ğŸ¾ Aunque estoy en modo de entrenamiento, mis bigotes de gato detectan que necesitas ayuda. Â¡AquÃ­ estoy!",
    "ğŸ˜» Â¡Hola humano! Estoy en modo simulaciÃ³n, pero mi corazÃ³n gatuno late con ganas de ayudarte.",
    "ğŸ± Â¡Ronroneo simulado activado! Â¿QuÃ© aventura planearemos hoy?",
    "ğŸ¾ En modo prÃ¡ctica, pero con toda la energÃ­a felina para asistirte. Â¡Miau!"
  ];
  
  // Agregar algo de variaciÃ³n basada en el mensaje
  const index = userMessage.length % responses.length;
  return responses[index];
}

/**
 * FunciÃ³n para probar la conexiÃ³n OpenAI
 * @returns {Promise<Object>} Estado de la conexiÃ³n
 */
export async function testOpenAIConnection() {
  if (!openai) {
    return { 
      success: false, 
      message: 'OpenAI no configurado - modo simulaciÃ³n activo',
      mode: 'simulation'
    };
  }

  try {
    const completion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: 'user', content: 'Test' }],
      max_tokens: 5,
    });

    return { 
      success: true, 
      message: 'ConexiÃ³n OpenAI exitosa',
      mode: 'real',
      model: completion.model
    };
  } catch (error) {
    console.error('âŒ Error test OpenAI:', error);
    return { 
      success: false, 
      message: `Error: ${error.message}`,
      mode: 'error'
    };
  }
}
